{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\student-management-\n",
    "#\"C:\\\\Users\\\\conve\\\\ZA_Project\\\\chatbot-local-run\\\\student-management-\"\n",
    "#  git@github.com:Kavinkumar1070/Employee-Chat-Application.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import git\n",
    "import stat\n",
    "\n",
    "def clone_github_repo(repo_url, clone_dir):\n",
    "    \"\"\"Clone the GitHub repository to the local directory, retaining specified folders.\"\"\"\n",
    "    try:\n",
    "        git.Repo.clone_from(repo_url, clone_dir)\n",
    "        logging.info(f\"Cloned GitHub repo: '{repo_url}' into '{clone_dir}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error cloning repository: {e}\")\n",
    "\n",
    "def copy_project_to_directory(source_directory, target_directory):\n",
    "    \"\"\"Copy the entire project from source_directory to target_directory, retaining specified folders.\"\"\"\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        for item in os.listdir(source_directory):\n",
    "            source_path = os.path.join(source_directory, item)\n",
    "            target_path = os.path.join(target_directory, item)\n",
    "\n",
    "            if os.path.isdir(source_path):\n",
    "                shutil.copytree(source_path, target_path, dirs_exist_ok=True)\n",
    "            else:\n",
    "                shutil.copy2(source_path, target_path)\n",
    "\n",
    "        logging.info(f\"Copied project from '{source_directory}' to '{target_directory}'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to copy project: {e}\")\n",
    "\n",
    "def remove_readonly(func, path, excinfo):\n",
    "    \"\"\"Function to remove readonly files before deleting.\"\"\"\n",
    "    os.chmod(path, stat.S_IWRITE)  # Change the file's permission to writable\n",
    "    func(path)  # Retry the operation\n",
    "\n",
    "def clean_folder(folder_path):\n",
    "    \"\"\"Removes all files and subdirectories in the specified folder, including the .git directory.\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        logging.warning(f\"The folder {folder_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    git_dir = os.path.join(folder_path, '.git')\n",
    "    if os.path.exists(git_dir):\n",
    "        try:\n",
    "            shutil.rmtree(git_dir, onerror=remove_readonly)\n",
    "            logging.info(f\"Removed directory: {git_dir}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting {git_dir}: {e}\")\n",
    "\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        try:\n",
    "            if os.path.isfile(item_path):\n",
    "                os.remove(item_path)\n",
    "                logging.info(f\"Removed file: {item_path}\")\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path, onerror=remove_readonly)\n",
    "                logging.info(f\"Removed directory: {item_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting {item_path}: {e}\")\n",
    "\n",
    "    logging.info(f\"All accessible files and subdirectories in {folder_path} have been removed.\")\n",
    "\n",
    "\n",
    "\n",
    "def clone_code_to_cwd():\n",
    "    \"\"\"Main function to clone or copy a project and retain specified folders.\"\"\"\n",
    "    fixed_target_directory = os.path.join(os.getcwd(), 'new_project')\n",
    "\n",
    "    # Clean the target directory before processing\n",
    "    \n",
    "\n",
    "    # Determine whether to process from local directory or GitHub\n",
    "    source_type = input(\"Do you want to process from 'local' or 'github'? \").strip().lower()\n",
    "    \n",
    "\n",
    "    if source_type == 'local':\n",
    "        source_directory = input(\"Enter the path to the local directory: \").strip()\n",
    "        if not os.path.exists(source_directory):\n",
    "            print(f\"The directory '{source_directory}' does not exist.\")\n",
    "            return\n",
    "        \n",
    "        clean_folder(fixed_target_directory)\n",
    "        copy_project_to_directory(source_directory, fixed_target_directory)\n",
    "\n",
    "    elif source_type == 'github':\n",
    "        repo_url = input(\"Enter the GitHub repository URL: \").strip()\n",
    "        clean_folder(fixed_target_directory)\n",
    "        clone_github_repo(repo_url, fixed_target_directory)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 'local' or 'github'.\")\n",
    "        return\n",
    "\n",
    "    print('Cloning/Copying Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def find_folder(target_folder_name, search_path):\n",
    "    \"\"\"\n",
    "    Finds the target folder in the given search path and returns the full path.\n",
    "    If the folder is not found, returns None.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(search_path):\n",
    "        if target_folder_name in dirs:\n",
    "            found_folder_path = os.path.join(root, target_folder_name)\n",
    "            logging.info(f\"Found folder: {found_folder_path}\")\n",
    "            return found_folder_path\n",
    "    logging.warning(f\"Folder '{target_folder_name}' not found in '{search_path}'\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def copy_selected_folders(source_directory, target_directory, selected_folders, root_directory):\n",
    "    \"\"\"\n",
    "    Copies selected folders from source_directory to target_directory.\n",
    "    Checks if the root_directory exists in source_directory before proceeding.\n",
    "    \"\"\"\n",
    "    # Check if the root directory exists in the source directory\n",
    "    root_folder_path = find_folder(root_directory, source_directory)\n",
    "    if not root_folder_path:\n",
    "        logging.error(f\"Root directory '{root_directory}' not found in '{source_directory}'. Aborting copy process.\")\n",
    "        return  # Exit the function if the root directory is not found\n",
    "    \n",
    "    # Ensure the target directory exists\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate over the selected folders\n",
    "    for folder in selected_folders:\n",
    "        folder_path = find_folder(folder, root_folder_path)  # Use find_folder to get the full path inside root_directory\n",
    "\n",
    "        # Check if the folder was found\n",
    "        if folder_path:\n",
    "            target_folder_path = os.path.join(target_directory, os.path.basename(folder_path))\n",
    "            try:\n",
    "                # Copy the entire folder to the target directory\n",
    "                shutil.copytree(folder_path, target_folder_path)\n",
    "                logging.info(f\"Copied folder: '{folder_path}' to '{target_folder_path}'\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to copy '{folder}': {e}\")\n",
    "        else:\n",
    "            logging.warning(f\"Folder '{folder}' does not exist in the root directory '{root_directory}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clone_code_to_cwd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclone_code_to_cwd\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clone_code_to_cwd' is not defined"
     ]
    }
   ],
   "source": [
    "clone_code_to_cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Removed directory: c:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers\n",
      "INFO:root:Removed directory: c:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\schemas\n",
      "INFO:root:All accessible files and subdirectories in c:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src have been removed.\n",
      "INFO:root:Found folder: C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\\student-management-\\src\n",
      "INFO:root:Found folder: C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\\student-management-\\src\\routers\n",
      "INFO:root:Copied folder: 'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\\student-management-\\src\\routers' to 'c:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers'\n",
      "INFO:root:Found folder: C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\\student-management-\\src\\schemas\n",
      "INFO:root:Copied folder: 'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\\student-management-\\src\\schemas' to 'c:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\schemas'\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "language = \"python\"\n",
    "root_directory = \"src\"\n",
    "routers_ =  \"routers\"\n",
    "schemas_ = \"schemas\"\n",
    "project_directory = r\"C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Cloned_Project\"  # Path to the main folder\n",
    "current_working_directory = os.getcwd()  # Get the current working directory\n",
    "target_directory = os.path.join(current_working_directory, root_directory)  # Target directory\n",
    "selected_folders = [routers_, schemas_]  # Specify the folders to copy\n",
    "clean_folder(target_directory)\n",
    "copy_selected_folders(project_directory, target_directory, selected_folders, root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Function to find schema imports in a single router file\n",
    "def find_schema_imports_in_router(router_file_path):\n",
    "    schema_imports = set()  # Use a set to avoid duplicates\n",
    "\n",
    "    # Updated regex pattern to match both single-line and multiline imports\n",
    "    import_pattern_start = re.compile(rf'^(from\\s+({root_directory}(\\.\\w+)*\\.{schemas_}\\.\\w+)\\s+import\\s+(.+))')\n",
    "    import_pattern_continue = re.compile(r'^\\s*(.+)')  # Pattern for multiline imports\n",
    "\n",
    "    try:\n",
    "        with open(router_file_path, 'r') as f:\n",
    "            multiline_import = False\n",
    "            current_imports = []\n",
    "            current_schema = None\n",
    "            \n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = re.sub(r'#.*$', '', line).strip()  # Remove comments and strip whitespace\n",
    "\n",
    "                if multiline_import:\n",
    "                    # We're in the middle of a multiline import\n",
    "                    match_continue = import_pattern_continue.match(line)\n",
    "                    if match_continue:\n",
    "                        part = match_continue.group(1).strip()\n",
    "                        current_imports.append(part)\n",
    "                        if part.endswith(')'):  # End of multiline import\n",
    "                            multiline_import = False\n",
    "                            classes = ''.join(current_imports).replace(')', '').replace('(', '').split(',')\n",
    "                            classes = [cls.strip() for cls in classes if cls.strip()]\n",
    "                            schema_imports.add((current_schema, tuple(classes)))  # Add multiline import\n",
    "                            current_imports = []  # Reset\n",
    "                    continue\n",
    "                \n",
    "                match_start = import_pattern_start.match(line)\n",
    "                if match_start:\n",
    "                    # Capture details from the matched line\n",
    "                    schema_name = match_start.group(2)  # Schema name\n",
    "                    imports = match_start.group(4).strip()  # Imported classes/functions\n",
    "\n",
    "                    if '(' in imports:  # Start of a multiline import\n",
    "                        multiline_import = True\n",
    "                        current_schema = schema_name\n",
    "                        current_imports = [imports]  # Start collecting imports\n",
    "                    else:\n",
    "                        # Single-line import\n",
    "                        classes = [cls.strip() for cls in imports.split(',')]\n",
    "                        schema_imports.add((schema_name, tuple(classes)))  # Store schema filename and classes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {router_file_path}: {e}\")\n",
    "\n",
    "    return schema_imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Adjust the path according to your directory structure\n",
    "# controller_path = r'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers\\students.py'\n",
    "# found_imports = find_schema_imports_in_router(controller_path)\n",
    "# print(found_imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "def extract_class_code(schema_file, classes):\n",
    "    # Read the content of the schema file\n",
    "    with open(schema_file, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Customize the prompt based on the filename and classes\n",
    "    prompt = f\"\"\"\n",
    "Please extract only the definitions of the following classes and their parent classes from the provided Python code dynamically:\n",
    "- For each class, check its fields, inheritance, and methods. If the class inherits from any other class or references Enums (like LeaveDuration, LeaveStatus) within the file, include those as well.\n",
    "- Ensure that all parent classes, fields, and validators used within the requested classes are captured.\n",
    "- Exclude all other unrelated classes.\n",
    "- Keep the output in the original Python code format.\n",
    " \n",
    "The classes to extract are:\n",
    "{', '.join(classes)}.\n",
    " \n",
    "Here is the Python code:\n",
    "{file_content}\n",
    " \n",
    "Ensure the response is enclosed with `~~~` before and after the output.\n",
    "\"\"\"\n",
    "\n",
    "    # Set up the Groq API key\n",
    "    client = Groq(\n",
    "        api_key=\"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\",\n",
    "    )\n",
    "\n",
    "    # Make the API call to the Groq model\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }],\n",
    "        model=\"llama3-70b-8192\"\n",
    "    )\n",
    "\n",
    "    # Extract the response content\n",
    "    natural_language_explanation = response.choices[0].message.content.strip()\n",
    "    json_start_idx = natural_language_explanation.find(\"~~~\") + 3\n",
    "    json_end_idx = natural_language_explanation.rfind(\"~~~\") \n",
    "    if json_start_idx > -1 and json_end_idx > json_start_idx:\n",
    "        result = natural_language_explanation[json_start_idx:json_end_idx].strip()\n",
    "    else:\n",
    "        result = \"No valid response found.\"  # Add a fallback if markers aren't present\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing schema file: src/schemas/students.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted classes from src/schemas/students.py and pasted into src/routers\\students.py.\n"
     ]
    }
   ],
   "source": [
    "routers_directory = f\"{root_directory}/{routers_}\"  # Adjust this path if necessary\n",
    "#print(routers_directory)\n",
    "# Iterate over each router file in the directory\n",
    "for root, _, files in os.walk(routers_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.py') and not file.startswith('__'):\n",
    "            router_file_path = os.path.join(root, file)\n",
    "            #print(router_file_path)\n",
    "            # Find schema imports in the current router file\n",
    "            schema_imports = find_schema_imports_in_router(router_file_path)\n",
    "            #print(schema_imports)\n",
    "            for schema_name, classes in schema_imports:\n",
    "                #print(schema_name)\n",
    "                #schema_file_path = f\"{root_directory}/{schemas_}/{schema_name.replace(f'{root_directory}.{schemas_}.', '')}.py\"  # Adjust the path accordingly\n",
    "                schema_file_path = f\"{root_directory}/{schemas_}/{schema_name.split('.')[-1]}.py\"\n",
    "                print(f\"Processing schema file: {schema_file_path}\")  # Debugging statement\n",
    "                \n",
    "                # Extract class code from the schema file\n",
    "                class_codes = extract_class_code(schema_file_path, classes)\n",
    "                \n",
    "                # Write the extracted class code back into the router file\n",
    "                try:\n",
    "                    with open(router_file_path, 'a') as router_file:  # Append to the router file\n",
    "                        router_file.write(f\"\\n\\n# Inserted class {classes} definitions from {schema_file_path}\\n\")\n",
    "                        router_file.write(class_codes)\n",
    "                    \n",
    "                    print(f\"Extracted classes from {schema_file_path} and pasted into {router_file_path}.\")  # Success message\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to {router_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "def convert_models_code_to_natural_language(code_content, filename=None):\n",
    "    prompt = (\n",
    "    f\"\"\"Please analyze the following {f'code from {filename}' if filename else 'code'} and provide the details as specified below.\n",
    "    \n",
    "    Convert the code into natural language and capture the following details for each function and class:\n",
    "\n",
    "    ### Function and API Route Details:\n",
    "    \n",
    "    * **Prefix**: Capture the URL prefix for the API route, if present. If none, indicate \"none.\" If the prefix includes versioning (e.g., `/v1`), include that as well.\n",
    "    * **Function Name**: Capture the exact function or method name that handles the API request.\n",
    "    * **Roles**: Identify roles (e.g., 'admin', 'employee') that can access the function. Check in middleware, decorators, annotations, or similar mechanisms. If no roles are defined, state \"none.\"\n",
    "    * **URL/Endpoint**: Capture the specific URL or endpoint the function handles.\n",
    "    * **HTTP Method**: Capture the HTTP method (e.g., GET, POST, PUT, DELETE).\n",
    "    \n",
    "    ### Parameter Details:\n",
    "    \n",
    "    * **Path Parameters**:\n",
    "        + For each path parameter:\n",
    "            - **Parameter Name**: The name of the parameter.\n",
    "            - **Data Type**: The expected data type (e.g., string, integer,date,boolean,float,EmailStr,enum,list[enum/class],list,list[str],list[int]).\n",
    "            - **Validations**: Any validation constraints (e.g., min/max values, regex). If none, indicate \"none.\"\n",
    "            - **Field Requirement**: Whether the parameter is \"required\" or \"optional\".\n",
    "    \n",
    "    * **Query or Body Parameters**: If the function receives class-based payloads (e.g., Pydantic models), provide the name of the class.\n",
    "    \n",
    "    * **Class Parameters**:\n",
    "        + Capture all class parameters, including injected instances, dependencies, or request bodies passed to the function.\n",
    "    \n",
    "    ### Class Definitions:\n",
    "    \n",
    "    * **Class Name**: Name of the class or model.\n",
    "    * **Fields**: \n",
    "        - For each field in the class, capture:\n",
    "            + **Field Name**: Name of the field.\n",
    "            + **Data Type**: check the Datatype of the field if its in [string, integer,date,boolean,float,EmailStr,list,list,list[str],list[int]] else check any enum or any class matches name then convert it datatype as enum and adjust required , validation field accordingly  or return value none . \n",
    "                                if optional[int] provide means  considered datatype - integer, field requirements- optional\n",
    "            + **Validations**: Any validation constraints (e.g., length, regex, ranges). If none, state \"none.\"\n",
    "            + **Field Requirement**: Whether the field is \"required\" or \"optional.\"\n",
    "        **check twice to fill the fields and values . and also check datatype classes too.\n",
    "    \n",
    "    ### Example Output Format:\n",
    "    \n",
    "    #### Function Example 1:\n",
    "    * **Prefix**: `/admin`\n",
    "    * **Function Name**: `update_employee_data`\n",
    "    * **Roles**: `admin`\n",
    "    * **URL/Endpoint**: `/employees/{{employee_id}}`\n",
    "    * **HTTP Method**: `PUT`\n",
    "    * **Path Parameters**:\n",
    "        - `employee_id`: `string`, `required`, `None`\n",
    "    * **Class Parameters**: `EmployeeUpdate`\n",
    "    \n",
    "    #### Function Example 2:\n",
    "    * **Prefix**: `/admin`\n",
    "    * **Function Name**: `read_employee`\n",
    "    * **Roles**: `admin`\n",
    "    * **URL/Endpoint**: `/employees/{{employee_id}}`\n",
    "    * **HTTP Method**: `GET`\n",
    "    * **Path Parameters**:\n",
    "        - `employee_id`: `integer`, `required`\n",
    "    * **Class Parameters**: `None`\n",
    "    \n",
    "    #### Class Example:\n",
    "    * **Class Name**: `EmployeeUpdate`\n",
    "        - `firstname`: `string`, `required`, `None`\n",
    "        - `lastname`: `string`, `optional`, `None`\n",
    "        - `dateofbirth`: `date`, `optional`, `YYYY-MM-DD`\n",
    "        - `email`: `EmailStr`, `required`, `None`\n",
    "        - `nationality`: `string`, `optional`, `None`\n",
    "        - `mobile_number`: `integer`, `required`, `must be 10 digit number`\n",
    "\n",
    "    **Enum Definitions:**\n",
    "\n",
    "        * **Enum Name: `gender`**\n",
    "        \t+ `ONE_DAY`: `\"male\"`\n",
    "        \t+ `HALF_DAY`: `\"female\"`\n",
    "    \n",
    "    ### Code to Analyze:\n",
    "    {code_content}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    # Set up the Groq API key\n",
    "    client = Groq(\n",
    "        api_key=\"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\",\n",
    "    )\n",
    "    \n",
    "    # Make a request to the LLM\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-70b-8192\",\n",
    "        )\n",
    "        # Extract the response content\n",
    "        natural_language_explanation = response.choices[0].message.content\n",
    "        return natural_language_explanation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error communicating with LLM API: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read code from a file and process it\n",
    "def process_code_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            code_content = file.read()\n",
    "\n",
    "        # Call the conversion function\n",
    "        explanation = convert_models_code_to_natural_language(code_content, filename=os.path.basename(file_path))\n",
    "        return explanation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all files in a folder\n",
    "def process_code_folder(folder_path):\n",
    "    try:\n",
    "        # Loop through each file in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Process only files (ignore subdirectories)\n",
    "            if os.path.isfile(file_path):\n",
    "                explanation = process_code_file(file_path)\n",
    "                \n",
    "                if explanation:\n",
    "                    # Save the explanation to a .txt file with the same name as the original file\n",
    "                    output_file = os.path.splitext(filename)[0] + '.txt'\n",
    "                    output_path = os.path.join(folder_path, output_file)\n",
    "\n",
    "                    with open(output_path, 'w') as f:\n",
    "                        f.write(explanation)\n",
    "                    print(f\"Processed {filename}, saved explanation to {output_file}\")\n",
    "                else:\n",
    "                    print(f\"Could not process {filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed students.py, saved explanation to students.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed __init__.py, saved explanation to __init__.txt\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Process all files in a folder\n",
    "folder_path = r'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers'  # Replace with your folder path\n",
    "process_code_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_api_details_from_text(text):\n",
    "    # Construct a prompt to instruct the model\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following text and extract the details for each endpoint in the specified format:\n",
    "\n",
    "## For payload - include both path parameters and class parameters - explain everything in structure fieldname - for each field datatype,field requirement,validation.\n",
    "# check the Datatype of the field if its in [string, integer,date,boolean,float,EmailStr,list,list[str],list[int]] , else check any enum or any class matches name then convert it datatype as enum and adjust required , validation field accordingly  or return value none .\n",
    "# if boolean means validation [true,false] , if list[enum/class] has class means considered like enum process\n",
    "#convert datatype has structure like this Optional[int],Optional[str],etc... into integer,string etc..\n",
    "Expected format of output is like json:\n",
    "{{\n",
    "    \"function name\": {{\n",
    "        \"project\": \"function name\",\n",
    "        \"url\": \"url/endpoint\",\n",
    "        \"method\": \"POST/GET/PUT/DELETE/etc.\",\n",
    "        \"Roles\": [\"role1\", \"role2\", ...],\n",
    "        \"payload\": {{\n",
    "            \"path_param\":{{\n",
    "            \"field_name1\": {{\n",
    "                \"datatype\": \"string/integer/enum/etc.\",\n",
    "                \"required\": true,\n",
    "                \"validation\": \"choices/format/length/etc. or None.\"\n",
    "            }},\n",
    "            }},\n",
    "            \"class_param\": {{\n",
    "                \"class_field1\": {{\n",
    "                    \"datatype\": \"string/integer/etc.\",\n",
    "                    \"required\": true,\n",
    "                    \"validation\": \"None\"\n",
    "                }},\n",
    "                ...\n",
    "            }},\n",
    "            ...\n",
    "        }}\n",
    "    }},\n",
    "    \"get employee details\": {{\n",
    "        \"project\": \"get employee details\",\n",
    "        \"url\": \"employee/edrfghj\",\n",
    "        \"method\": \"GET\",\n",
    "        \"Roles\": [\"employee\", \"admin\", ...],\n",
    "        \"payload\": {{\n",
    "            \"path_param\":{{\n",
    "            \"employee_id\": {{\n",
    "                \"datatype\": \"integer\",\n",
    "                \"required\": true,\n",
    "                \"validation\": \"None\"\n",
    "            }},\n",
    "            \"type\": {{\n",
    "                \"datatype\": \"enum\",\n",
    "                \"required\": true,\n",
    "                \"validation\": [\"a\",\"b\",\"c\"]\n",
    "            }}\n",
    "            ...\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "}}\n",
    "If no fields are provided for the Payload, return an empty dictionary: {{}}. If any fields are mentioned, include them in the specified dictionary format.\n",
    "\n",
    "Please ensure that:\n",
    "- You do not omit any details, including optional ones.\n",
    "- The output strictly follows the format shown above without additional phrases like \"and so on.\"\n",
    "- Include any nested class parameters fully, detailing their fields, data types, required status, and validations.\n",
    "\n",
    "Here is the text:\n",
    "{text}\n",
    "\n",
    "Please enclose the response with `~~~` before and after the output.\n",
    "\"\"\"\n",
    "\n",
    "    # Set up the Groq API key\n",
    "    client = Groq(\n",
    "        api_key=\"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\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    # Extract the content from the response\n",
    "    natural_language_explanation = response.choices[0].message.content.strip()\n",
    "    # Locate the JSON section based on the '~~~' markers\n",
    "    json_start_idx = natural_language_explanation.find(\"~~~\") + 3\n",
    "    json_end_idx = natural_language_explanation.rfind(\"~~~\")\n",
    "    # Check if markers are present\n",
    "    if json_start_idx > -1 and json_end_idx > json_start_idx:\n",
    "        result = natural_language_explanation[json_start_idx:json_end_idx].strip()\n",
    "        result = escape_backslashes(result)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_backslashes(text):\n",
    "    # Escape all backslashes in regular expressions for JSON compatibility\n",
    "    return text.replace(\"\\\\\", \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "def final_formatting(text):\n",
    "    # Construct a prompt to instruct the model\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following API documentation text and extract the details for each endpoint in the specified format:\n",
    "##add new details in response\n",
    "**project description** - write a description based on method and function name.\n",
    "**description** - write a description based on method, function name, and field name.\n",
    "**Both are used for capturing the project or filling field values from user query, so write accordingly.**\n",
    "\n",
    "**Rename validation into --format**\n",
    "\n",
    "**add assigned value** - \"assigned\": \"None\" for all.\n",
    "\n",
    "Expected format of output is like json:\n",
    "{{\n",
    "    \"function name\": {{\n",
    "        \"project\": \"function name\",\n",
    "        \"project description\": \"about project\",\n",
    "        \"url\": \"url/endpoint\",\n",
    "        \"method\": \"POST/GET/PUT/DELETE/etc.\",\n",
    "        \"Roles\": [\"role1\", \"role2\", ...],\n",
    "        \"payload\": {{\n",
    "            \"field_name1\": {{\n",
    "                \"description\": \"about field for function name\",\n",
    "                \"datatype\": \"string/integer/enum/etc.\",\n",
    "                \"required\": true,\n",
    "                \"format\": \"value\", \n",
    "                \"assigned\": \"None\"\n",
    "            }},\n",
    "            \"gender\": {{\n",
    "                \"description\": \"gender needed for function name\",\n",
    "                \"datatype\": \"enum\",\n",
    "                \"required\": true,\n",
    "                \"format\": [\"male\", \"female\"],\n",
    "                \"assigned\": \"None\"\n",
    "            }},\n",
    "            \"father_contact_no\": {{\n",
    "                \"description\": \"Father's contact number for function name\",\n",
    "                \"datatype\": \"integer\",\n",
    "                \"required\": true,\n",
    "                \"format\": \"must be at least 10 digits long\",\n",
    "                \"assigned\": \"None\"\n",
    "            }},\n",
    "            ...\n",
    "        }}\n",
    "    }},\n",
    "    \"get employee details\": {{\n",
    "        \"project\": \"get employee details\",\n",
    "        \"project description\": \"Retrieve the employee details by employee id\",\n",
    "        \"url\": \"employee/edrfghj\",\n",
    "        \"method\": \"GET\",\n",
    "        \"Roles\": [\"employee\", \"admin\", ...],\n",
    "        \"payload\": {{\n",
    "            \"employee_id\": {{\n",
    "                \"description\": \"employee ID to get employee details\",\n",
    "                \"datatype\": \"integer\",\n",
    "                \"required\": true,\n",
    "                \"format\": \"None\",\n",
    "                \"assigned\": \"None\"\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Here is the text:\n",
    "{text}\n",
    "\n",
    "Please enclose the response with `~~~` before and after the output.\n",
    "\"\"\"\n",
    "\n",
    "    # Set up the Groq API key\n",
    "    client = Groq(\n",
    "        api_key=\"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\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "        )\n",
    "\n",
    "        # Extract the content from the response\n",
    "        natural_language_explanation = response.choices[0].message.content.strip()\n",
    "        #print(natural_language_explanation)\n",
    "        # Locate the JSON section based on the '~~~' markers\n",
    "        json_start_idx = natural_language_explanation.find(\"~~~\") + 3\n",
    "        json_end_idx = natural_language_explanation.rfind(\"~~~\")\n",
    "\n",
    "        # Check if markers are present\n",
    "        if json_start_idx > -1 and json_end_idx > json_start_idx:\n",
    "            result = natural_language_explanation[json_start_idx:json_end_idx].strip()\n",
    "            result = escape_backslashes(result)\n",
    "            #print(result)\n",
    "            try:\n",
    "                # Load the sanitized JSON\n",
    "                result = json.loads(result)\n",
    "                print('Parsed JSON successfully.')\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Final JSON parsing error: {e}\")\n",
    "                result = \"No valid response found.\"\n",
    "        else:\n",
    "            result = \"No valid response found.\"  # Add a fallback if markers aren't present\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {e}\")\n",
    "        result = \"No valid response found.\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the text file containing the API documentation\n",
    "# with open(r'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers\\students.txt', 'r') as file:\n",
    "#     api_text = file.read()\n",
    "\n",
    "# # Extract API details\n",
    "# api_info = extract_api_details_from_text(api_text)\n",
    "\n",
    "# # Print the extracted API details\n",
    "# print(api_info)\n",
    "\n",
    "# # Extract API details\n",
    "# api_info1 = final_formatting(api_info)\n",
    "\n",
    "# # Print the extracted API details\n",
    "# print(api_info1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def process_files(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Check if it is a file and has a .txt extension\n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            # Read the text file containing the API documentation\n",
    "            with open(file_path, 'r') as file:\n",
    "                api_text = file.read()\n",
    "\n",
    "            # Extract API details (Assuming `extract_api_details_from_text` returns a dictionary or similar JSON-serializable structure)\n",
    "            api_info = extract_api_details_from_text(api_text)\n",
    "            api_info1 = final_formatting(api_info)\n",
    "\n",
    "            # Define output file path, changing the extension to .json\n",
    "            output_file_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.json\")\n",
    "\n",
    "            # Save the extracted API details to a JSON file\n",
    "            with open(output_file_path, 'w') as output_file:\n",
    "                json.dump(api_info1, output_file, indent=4)\n",
    "\n",
    "            print(f\"Processed {filename} and saved as {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed JSON successfully.\n",
      "Processed students.txt and saved as C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Json_Output\\students.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed JSON successfully.\n",
      "Processed __init__.txt and saved as C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Json_Output\\__init__.json\n"
     ]
    }
   ],
   "source": [
    "input_folder  = r\"C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\src\\routers\"\n",
    "output_folder = r\"C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Json_Output\"\n",
    "process_files(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# def process_json_files(input_directory, roles_directory):\n",
    "#     # Create the roles directory if it doesn't exist\n",
    "#     os.makedirs(roles_directory, exist_ok=True)\n",
    "\n",
    "#     # Process each JSON file in the input directory\n",
    "#     for filename in os.listdir(input_directory):\n",
    "#         if filename.endswith('.json'):\n",
    "#             file_path = os.path.join(input_directory, filename)\n",
    "#             with open(file_path, 'r') as file:\n",
    "#                 try:\n",
    "#                     data = json.load(file)\n",
    "\n",
    "#                     # Process each project in the JSON data\n",
    "#                     for key, project in data.items():\n",
    "#                         project_info = {\n",
    "#                             \"project\": project[\"project\"],\n",
    "#                             \"project_description\": project[\"project description\"],\n",
    "#                             \"url\": project[\"url\"],\n",
    "#                             \"method\": project[\"method\"],\n",
    "#                             \"payload\": project.get(\"payload\", {})\n",
    "#                         }\n",
    "\n",
    "#                         # Save project info to each role's file\n",
    "#                         for role in project[\"Roles\"]:\n",
    "#                             role_filename = os.path.join(roles_directory, f\"{role}.json\")\n",
    "\n",
    "#                             # Append the project info to the role's file\n",
    "#                             if os.path.exists(role_filename):\n",
    "#                                 with open(role_filename, 'r+') as role_file:\n",
    "#                                     role_data = json.load(role_file)\n",
    "#                                     role_data[key] = project_info\n",
    "#                                     role_file.seek(0)\n",
    "#                                     json.dump(role_data, role_file, indent=4)\n",
    "#                                     role_file.truncate()\n",
    "#                             else:\n",
    "#                                 with open(role_filename, 'w') as role_file:\n",
    "#                                     json.dump({key: project_info}, role_file, indent=4)\n",
    "\n",
    "#                 except json.JSONDecodeError:\n",
    "#                     print(f\"Error decoding JSON from file: {file_path}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"An error occurred while processing file {file_path}: {e}\")\n",
    "\n",
    "#     print(f\"Project details saved in '{roles_directory}' folder.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def process_json_files(input_directory, roles_directory, user_roles):\n",
    "    # Create the roles directory if it doesn't exist\n",
    "    os.makedirs(roles_directory, exist_ok=True)\n",
    "    \n",
    "    # Create noroles.json file\n",
    "    noroles_file_path = os.path.join(roles_directory, \"noroles.json\")\n",
    "    noroles_data = {}\n",
    "\n",
    "    # Process each JSON file in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    # Process each project in the JSON data\n",
    "                    for key, project in data.items():\n",
    "                        project_info = {\n",
    "                            \"project\": project[\"project\"],\n",
    "                            \"project description\": project[\"project description\"],\n",
    "                            \"url\": project[\"url\"],\n",
    "                            \"method\": project[\"method\"],\n",
    "                            \"payload\": project.get(\"payload\", {})\n",
    "                        }\n",
    "\n",
    "                        # Check if any roles match the user-provided roles\n",
    "                        matched = False\n",
    "                        for role in project[\"Roles\"]:\n",
    "                            if role in user_roles:\n",
    "                                matched = True\n",
    "                                role_filename = os.path.join(roles_directory, f\"{role}.json\")\n",
    "\n",
    "                                # Append the project info to the role's file\n",
    "                                if os.path.exists(role_filename):\n",
    "                                    with open(role_filename, 'r+') as role_file:\n",
    "                                        role_data = json.load(role_file)\n",
    "                                        role_data[key] = project_info\n",
    "                                        role_file.seek(0)\n",
    "                                        json.dump(role_data, role_file, indent=4)\n",
    "                                        role_file.truncate()\n",
    "                                else:\n",
    "                                    with open(role_filename, 'w') as role_file:\n",
    "                                        json.dump({key: project_info}, role_file, indent=4)\n",
    "\n",
    "                        # If no roles matched, add to noroles.json\n",
    "                        if not matched:\n",
    "                            noroles_data[key] = project_info\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON from file: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing file {file_path}: {e}\")\n",
    "\n",
    "    # Save projects with no matching roles to noroles.json\n",
    "    if noroles_data:\n",
    "        with open(noroles_file_path, 'w') as noroles_file:\n",
    "            json.dump(noroles_data, noroles_file, indent=4)\n",
    "\n",
    "    print(f\"Project details saved in '{roles_directory}' folder.\")\n",
    "    if noroles_data:\n",
    "        print(f\"Projects with no matching roles saved in '{noroles_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get user input for roles\n",
    "    num_roles = int(input(\"Enter the number of roles: \"))\n",
    "    user_roles = []\n",
    "    for _ in range(num_roles):\n",
    "        role = input(\"Enter role name: \").strip()\n",
    "        user_roles.append(role)\n",
    "\n",
    "    # Define the input and roles directory\n",
    "    input_directory = r\"C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion\\Json_Output\"  # Replace with your JSON files directory\n",
    "    roles_directory = \"roles\"  # Directory to save the role-specific JSON files\n",
    "\n",
    "    # Process the JSON files with the user-provided roles\n",
    "    process_json_files(input_directory, roles_directory, user_roles)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: admin.json, Project: read_employee_route\n",
      "File: admin.json, Project: update_employee_data\n",
      "File: admin.json, Project: delete_employee_route\n",
      "File: admin.json, Project: create_employee\n",
      "File: admin.json, Project: read_employee\n",
      "File: admin.json, Project: update_employee_admin\n",
      "File: admin.json, Project: delete_employee_details\n",
      "File: admin.json, Project: get_leave_by\n",
      "File: admin.json, Project: get_leave_by_month\n",
      "File: admin.json, Project: get_leaves_by_employee\n",
      "File: admin.json, Project: delete_leave\n",
      "File: admin.json, Project: update_leave\n",
      "File: admin.json, Project: create_leave_calendar\n",
      "File: admin.json, Project: get_leave_calendar\n",
      "File: admin.json, Project: apply_leave\n",
      "File: admin.json, Project: create_role\n",
      "File: admin.json, Project: delete_role\n",
      "File: admin.json, Project: update_role\n",
      "File: admin.json, Project: get_roles\n",
      "File: admin.json, Project: assign_role_to_employee\n",
      "File: admin.json, Project: create_new_role_function\n",
      "File: admin.json, Project: read_role_functions\n",
      "File: admin.json, Project: update_functions\n",
      "File: admin.json, Project: delete_existing_role_function\n",
      "File: employee.json, Project: get_leaves_by_employee\n",
      "File: employee.json, Project: read_employee\n",
      "File: employee.json, Project: apply_leave\n",
      "File: employee.json, Project: get_leave_by\n",
      "File: employee.json, Project: get_leave_by_month\n",
      "File: employee.json, Project: delete_leave\n",
      "File: employee.json, Project: get_leave_calendar\n",
      "File: employee.json, Project: read_employee_route\n",
      "File: employee.json, Project: update_employee_data\n",
      "File: nonroles.json, Project: bot_response\n",
      "File: nonroles.json, Project: create_employee_route\n",
      "File: teamlead.json, Project: get_leaves_by_employee\n",
      "File: teamlead.json, Project: read_employee\n",
      "File: teamlead.json, Project: apply_leave\n",
      "File: teamlead.json, Project: get_leave_by\n",
      "File: teamlead.json, Project: get_leave_of_employee\n",
      "File: teamlead.json, Project: get_leave_by_month\n",
      "File: teamlead.json, Project: update_leave\n",
      "File: teamlead.json, Project: delete_leave\n",
      "File: teamlead.json, Project: get_leave_calendar\n",
      "File: teamlead.json, Project: get_leave_calendar_tl\n",
      "File: teamlead.json, Project: read_employee_route\n",
      "File: teamlead.json, Project: update_employee_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the path to the folder containing the JSON files\n",
    "folder_path = r'C:\\Users\\conve\\ZA_Project\\chatbot-local-run\\code-convertion - Copy\\ipy\\roles'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "                \n",
    "                # Iterate over each project in the JSON content\n",
    "                for key, value in data.items():\n",
    "                    project_name = value.get(\"project\", \"No project name found\")\n",
    "                    print(f\"File: {filename}, Project: {project_name}\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admin.json': ['read_employee_route', 'update_employee_data', 'delete_employee_route', 'create_employee', 'read_employee', 'update_employee_admin', 'delete_employee_details', 'get_leave_by', 'get_leave_by_month', 'get_leaves_by_employee', 'delete_leave', 'update_leave', 'create_leave_calendar', 'get_leave_calendar', 'apply_leave', 'create_role', 'delete_role', 'update_role', 'get_roles', 'assign_role_to_employee', 'create_new_role_function', 'read_role_functions', 'update_functions', 'delete_existing_role_function'], 'employee.json': ['get_leaves_by_employee', 'read_employee', 'apply_leave', 'get_leave_by', 'get_leave_by_month', 'delete_leave', 'get_leave_calendar', 'read_employee_route', 'update_employee_data'], 'nonroles.json': ['bot_response', 'create_employee_route'], 'teamlead.json': ['get_leaves_by_employee', 'read_employee', 'apply_leave', 'get_leave_by', 'get_leave_of_employee', 'get_leave_by_month', 'update_leave', 'delete_leave', 'get_leave_calendar', 'get_leave_calendar_tl', 'read_employee_route', 'update_employee_data']}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the results\n",
    "projects_dict = {}\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "                \n",
    "                # Initialize a list to store project names for the current file\n",
    "                project_names = []\n",
    "                \n",
    "                # Iterate over each project in the JSON content\n",
    "                for key, value in data.items():\n",
    "                    project_name = value.get(\"project\", \"No project name found\")\n",
    "                    project_names.append(project_name)\n",
    "                \n",
    "                # Store the project names list in the dictionary with the filename as the key\n",
    "                projects_dict[filename] = project_names\n",
    "            \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Print or use the resulting dictionary\n",
    "print(projects_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
